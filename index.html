<hr>

<h1>PARC - AI - League</h1>

<h2>AI League Challenge: Mining Innovation Challenge (MIC)</h2>

<p>| Due | Scoring (100) | Activity |
| ---:| :-------------| :--------|
| 3/31| 0%            | <span style="color:green">Registration deadline / Phase 1 start</span> |
| 4/3 | 10%               | 1. Model definition (Pre-proposal) |
| 4/7| 0%             | 2. Proof-reader group definition  |
| 4/14| 0%            | <strong>3. Project Proposal document Submission</strong> |
| 4/14 - 4/19| 10%    | <strong>4. Live Proposal presentation</strong> |
| 4/20| 0%            | $\color{green}{<strong>5. Proposal Peer Evaluation</strong>}$ |
| 5/1 | 10%               | <strong>6. Final report and Project code submission</strong> |
| 6/1| 10%            | 7. Online final presentation (Phase 1) |
| 6/15| 0%            | <strong>8. Final Peer Evaluation (Pahse 1)</strong> |
| 6/25| <strong>60%</strong>           | <strong>9. Phase 1 Results are out</strong> |
| 6/30| 10%               | <strong>10. Submission of final models and/or weights</strong> |
| 7/xx| <strong>30% (50% for oral presentation and 50% for testings)</strong> | <strong>Live Final in Morocco</strong> <br /> [ ] Poster presentation <br /> [ ] Power Point (5 mn) <br /> [ ] Test of models on unseen data (7 mn) <br /> [ ] Possibility to join online |</p>

<h2>Overview</h2>

<p>All participants will complete a group project for the mining innovation challenge (MIC). This project involves reviewing existing literature, designing, executing and analyzing experiments using machine learning models.</p>

<p>Once groups are formed and registered. They will propose an experiment using a sketch of their final report, along with a proof of viability for their chosen implementation and dataset. The final implementation and write-up will be submitted by mid-June. An in-person 15 minute presentation will be given by each group during PARC in July by the finalists (the hard deadline is July 1st 2025). No late submissions will be accepted.</p>

<p>More details on each stage of the challenge project are provided below.</p>

<h2>Pre-proposal</h2>

<p>The challenge project will be completed in groups of 3-5 participants. Participants who have formed their groups should should be good to go.
Groups will be paired, and each group will proof-read and provide feedback to the other paired group. Feedback is encouraged at any time.</p>

<p>Group team registration is our first project due date.</p>

<p>Your group  will need to choose a paper from a top-tier conference or journal. A paper can only be chosen by a single group. If you need ideas on machine learning fields of research, here is a non-comprehensive suggestion of categories to look for:</p>

<ul>
<li>Computer Vision (CV): image classification, object detection, image to text, etc.</li>
<li>Natural Language Processing (NLP): text summarization, question answering, etc.</li>
<li>Meta Learning: transfer learning, few-shot learning, etc.</li>
</ul>

<h2>Detailed Project Milestones</h2>

<h3>1. Project Proposal Writeup (10% of final score)</h3>

<p>The project proposal's main goal is to at least build upon existing results of the chosen model, e.g., Neural Network. Each group will submit a proposal as a PDF document via email #TODO by the due date. The proposal will be scored out of 50 points.</p>

<ul>
<li>The proposal will be a 6 page sketch (draft) of the final report, with one page per section of the final report, one page for references, and a 1-pager specific to the proposal (‘Viability’).</li>
<li>Format: The full document should be six pages long, with each section on a separate page (11pt font, 1 inch margins).</li>
</ul>

<h4>Proposal Sections</h4>

<ul>
<li><p><strong>Section 1</strong>: Task Definition, Evaluation Protocol, and Data. Capture the intended task, dataset, and metrics, and include an associated reference.</p></li>
<li><p><strong>Section 2</strong>: Neural Network Machine Learning Model. Identify  the learning model to be utilized, along with the associated references. A draft outline of how the model will be summarized in this section is required, along with a description of any figures or tables to be used. Model constraints include:
If a framework does not run relatively easily for your group after carefully reading the documentation on how to install, run, and retrain it, or it is difficult to see where parameters and hyper-parameters might be changed - do not use such model(s)</p></li>
<li><p><strong>Section 3</strong>: Experiment Design. A table briefly sketching the research question(s), variables, and hypotheses, as described in the writeup requirements below, along with a bullet-point summary of expected modifications/code needed to run your experiment.</p></li>
<li><p><strong>Section 4</strong>: Experimental Results and Discussion.
Summary of the results that will be collected, and the tables and figures that you will use to present results.
How results will be used to test your hypothesis, and what you expect to learn about your research question(s) if the hypotheses are (a) confirmed, (2) contradicted, or (3) not clearly confirmed or contradicted. We want to avoid outcome (3) - thinking about the possibility often helps improve our experiment designs.</p></li>
<li><p><strong>Section 5</strong>: References. At least 1 page, with references for Sections 1, 2, and optionally Section 3</p></li>
<li><strong>Section 6</strong>: Viability Test: This is intended to confirm that you will be able to work with your intended model.
Provide output or a screenshot showing that you are able to run the model as provided in the framework that you are using. Also include the time needed to run the model on the test set, and the test set size for your task. The model does not need to be fit to the whole data.
Provide a second output or screen shot that clearly shows that you are able to train the model for 1 epoch over the dataset. Also include the time required to train for the one epoch, and the number of training samples.</li>
</ul>

<h3>2. Proposal Presentation (virtual 10%)</h3>

<p>The proposal presentation will take place online. The presentation will be scored out of 50 points (10 points per required talk element below, plus 10 points for questions).
Each group will have exactly 10 minutes each to present a summary of their project work to date.
Required 15 Minutes Presentation Content:
10 minutes talk (maximum; this will be timed); 5 minutes for questions. All group members should speak for at least 2 minutes.</p>

<ul>
<li><strong>Learning task and research question(s)</strong></li>
<li><strong>Learning model</strong></li>
<li><strong>Experiment design (including dataset)</strong></li>
<li><strong>Preliminary results, how they relate to the research question(s)</strong></li>
</ul>

<h3>3. Final Report and Project Code (10%)</h3>

<p>The report and code are expected to be prepared by the group as a whole, e.g., all participants should contribute to both the code and the final report.
Note that for the writeup, the technical depth, analysis, and clarity of the writing (including design, placement and formatting of figures and graphics) will be roughly equally weighted factors in the assigned score.
For evaluating code, the thoughtful use of existing operations built into the framework, code organization, and style will be factors in scoring.</p>

<h4>a. Final Code/Implementation</h4>

<p>The implementation will be scored out of 50 points; a rubric will be available #TODO showing specific criteria.
A .zip file containing your code, along with a README explaining how to install and run your system on a Linux/Mac/Windows machine is required. If your code requires a GPU, make sure you include this requirement as part of your README.
Participants are strongly encouraged to start from an existing framework. A (highly) partial list of possible frameworks include:</p>

<ul>
<li>Tensorflow</li>
<li>PyTorch</li>
<li>etc.
In choosing their research question(s)/topic(s), groups are strongly encouraged to download and play with a framework or two that look interesting, try some of the provided examples.</li>
</ul>

<h4>b. Final Report Writeup</h4>

<p>The final project report will be scored out of 50 points, a rubric will be available #TODO.
Below are the required sections for the writeup, along with notes regarding requirements for each section. The writeup must be 8-10 pages in length, with 11pt font, 1 inch margins, including figures, tables, and other graphics as appropriate, and with 1 page for references.
The following page lengths are encouraged, but may vary.</p>

<h4>c. Final Project Report Sections</h4>

<p><strong>(1 page) 1. Task Definition (Project description), Evaluation Protocol, and Data</strong>
With one or two figures illustrating the task, and how evaluation is performed
Include a reference for a paper or book defining the task and dataset - preferably from those who created the dataset in the form you are using. Cite this paper in your discussion, summarizing any other pertinent details of interest related to the task definition.</p>

<p><strong>(2 pages) 2. Neural Network / Machine Learning Model</strong></p>

<ul>
<li>Neural Network Learning Model Summary
<ul>
<li>Remember to include the loss metric used in training</li>
<li>Focus on defining the model clearly, explaining key pieces of the parts.</li>
</ul></li>
<li>Use figures where it will aid understanding. Figures created by groups are preferred; where figures, tables, etc. are taken from other documents, they must be explicitly cited so this is clear.</li>
<li>Focus your presentation on the parts of the algorithm that you will modify, to help motivate and provide context for your experiment.</li>
<li>1-3 reference(s) defining the model
<ul>
<li>Cite and summarize this in your discussion</li>
</ul></li>
</ul>

<p><strong>(2 pages) 3. Experiment</strong></p>

<ul>
<li>The research question(s) that your experiment addresses (but does not necessarily answer) - put another way, what do you hope to learn from the experiment?</li>
<li>Design:
<ul>
<li>Explicitly identify (organization in subsections and/or tables is fine):
<ul>
<li>Hypothesis: a falsifiable statement about the expected outcome of the experiment based on your understanding of the learning model, which is clearly motivated by your research question(s). This should be closely tied to the pertinent mathematical, algorithmic, and data/storage properties of the model associated with your research question(s).</li>
<li>Independent variables (Experimental Settings) that you will manipulate, e.g., hyper-parameters, model form, other learning parameters, etc.),</li>
<li>Control variables (Biases and Modeling assumptions) that will be held constant, but might alter the experiment outcome if this was not true, and</li>
<li>Dependent variables (Results Analysis) for observations made during and after systems are trained, e.g., performance metrics, learning curves, convergence intervals in number of epochs, etc.</li>
</ul></li>
</ul></li>
<li>Methodology. Identify the specific implementation/code base used, any required data processing, and a summary of modification/ code required for your available implementation to create and run the different conditions of your experiment.</li>
<li>Requirements:
<ul>
<li>You must make use of a baseline that you will compare your modifications (‘conditions’) against. This can include modifications to the original model, different dataset or different experimental settings. The choice of baseline must be motivated by your research question(s) and the model(s) involved.</li>
<li>Your research question(s) can be simple, but must be focused on building understanding of a learning model. “Will A perform better than B?” asks for a single observation in isolation; it does not test expected behavior based on a formal understanding (‘model’), and so is not a scientific research question.</li>
<li>The experiment should contain at least 3 conditions for one variable (not including grid-search or other methods to tune hyper-parameters for each condition_, to keep your effort excused and manageable in the available time frame. The conditions should be defined by changing one variable, e.g., network architecture, embedding size, different activation functions, etc.</li>
</ul></li>
</ul>

<p><strong>(2-3 pages) 4. Experimental Results and Discussion</strong>
Your analysis should read like a clear narrative - roughly, a well-guided tour of the results, whether they confirm or contradict your hypothesis, and what this tells you about your research question(s).</p>

<ul>
<li>Numeric results from your experiments in tables and/or figures. Include specific metric values wherever possible, e.g., at the top of bars in bar graphs.</li>
<li>Visualizations of results where helpful, e.g., learning curves, tables of metics, etc.</li>
<li>A discussion of whether these results support or contradict your hypothesis, and how this informs your understanding of the original research question(s), and possible next steps.</li>
</ul>

<p><strong>(1 page) References</strong></p>

<h3>4. Final Presentation (30%)</h3>

<p>The final presentation will be done in-person during PARC 2025. Each group member is required to speak for at least 1 minute. As in the proposal presentation, your final presentation should include:</p>

<ol>
<li>Learning task and research question(s)</li>
<li>Learning model(s)</li>
<li>Experiment design (including dataset and experiment settings modifications from the proposal)</li>
<li>Results, how they relate to the research question</li>
</ol>
